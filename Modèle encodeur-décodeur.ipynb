{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efaca370-9257-47cf-8b44-b476e12b0c1d",
   "metadata": {},
   "source": [
    "Dans ce notebook, je cherche à coder un algorithme qui permet de traduire une phrase simple en français vers l'anglais. Je me base sur ma compréhension de cette vidéo https://www.youtube.com/watch?v=FWQ2SvE-nbM et sur la décomposition des étapes par ChatGPT 4o. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3767db9-dc43-4e96-a71a-74e8693804b7",
   "metadata": {},
   "source": [
    "## Étape 1 : Créer un jeu de données avec des associations phrase en Anglais / phrase en Français. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "339aa6ec-aa14-4219-8fec-f328ae67e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    (\"je t'aime\", \"i love you\"),\n",
    "    (\"j'aime les pâtes\", \"i love pasta\"),\n",
    "    (\"bonjour\", \"hello\"),\n",
    "    (\"je suis fatigué\", \"i am tired\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ccd61-0afe-4935-9a76-2481e3152377",
   "metadata": {},
   "source": [
    "## Étape 2 : Encoder les phrases en indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee3ee9-5558-4ba9-b158-46835e6346dc",
   "metadata": {},
   "source": [
    "Pour coder cette deuxième étape, j'utilise le document colab en description de la vidéo cf. l'url du début."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a94b3ca7-e2d2-4b21-b41a-3cf3ddae7476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "#On installe tensor flow\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47320f0a-6b86-4b7a-a41c-d6a783f3a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c608785d-9c12-4e4d-9014-f9eac54702b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On importe la fonction one_hot qui nous permet d'associer à un mot un vecteur de la base canonique de dimension la taille du vocabulaire qu'on a\n",
    "# en bref base canonique de dim = voc_size\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81047c1b-710f-4eaa-a350-c24f17219f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#voc_size : de ce que j'ai compris on met ce qu'on veut on est pas obligé de prendre le nombre de mot exact qu'on a dans notre bdd\n",
    "voc_size=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb6a7233-7e3f-4251-8f9d-7b658321addf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[185, 151], [271, 117, 234], [267, 436, 304], [271, 117, 187], [116], [54], [185, 63, 196], [271, 257, 431]]\n"
     ]
    }
   ],
   "source": [
    "#One-hot representation : on utilise la fonction de tensor-flow\n",
    "#Là on vient prendre les phrases de chaque paire et les mots de chaque phrase \n",
    "onehot_repr=[one_hot(words,voc_size) for vec in pairs for words in vec]\n",
    "print(onehot_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbaf8b1-6bf5-40e8-afd4-c04d53fb74fb",
   "metadata": {},
   "source": [
    "J'ai l'impression qu'il va y avoir deux problèmes ici : \n",
    "- Un évoqué dans la vidéo c'est celui de la taille de nos vecteurs il faut que ce soit les mêmes pour pouvoir entraîner notre modèle mais ça j'ai déjà la solution vu que c'est dans la vidéo\n",
    "- L'autre problème pour moi c'est que vu qu'on dissocie nos paires dans le one-hot matching je pense qu'on perd l'équivalence entre les phrases. Pour ce second problème, je ne le considère pas pour le moment mais je garde en tête que ça risque d'être embêtant à un moment.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ed4a429-575f-4c6c-a9e4-fcc9749d2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fait tout pareil que Krish\n",
    "from tensorflow.keras.layers import Embedding \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbe70390-59b6-4c93-86a7-debbe2dc591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08b444e5-d63c-421a-bd25-8f02ea540434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 185 151]\n",
      " [  0   0 271 117 234]\n",
      " [  0   0 267 436 304]\n",
      " [  0   0 271 117 187]\n",
      " [  0   0   0   0 116]\n",
      " [  0   0   0   0  54]\n",
      " [  0   0 185  63 196]\n",
      " [  0   0 271 257 431]]\n"
     ]
    }
   ],
   "source": [
    "## pre padding : j'ai pas trop compris l'intérêt d'utiliser du pre-padding plutôt que post-padding et inversement donc on part sur pre padding\n",
    "sent_length=5 #taille des vecteurs que je vais avoir \n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length) #on ajoute des 0 avant la séquence one-hot pour avoir un vecteur de la bonne taille \n",
    "print(embedded_docs) #Maintenant on constate que tout le monde à la même taille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b5cc83b-7cba-4326-bd77-f78d61a01a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10 feature dimesnions\n",
    "# en gros je choisis le nombre de dimensions que je veux donner à chaque token\n",
    "dim=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5e87a8ad-1d16-4e70-a161-ce1bf7b23147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Là j'utilise tout comme Krish\n",
    "model=Sequential() #ça ça me permet de créer un modèle où je vais pouvoir empiler différentes couches qui prennent 1 entrée et 1 sortie et tq chaque couches se succèdent\n",
    "model.add(Embedding(voc_size,dim)) #là j'ajoute ma couche de Embedding avec le nombre de dimensions\n",
    "model.compile('adam','mse') # \"adam\" c'est ce qui ajuste les poids pendant l'entraînement \"mse\" c'est ma mean squared error que j'utilise pour la régression\n",
    "model.build(input_shape=(None, sent_length)) # c'est pour remplacer le input_shape du code d'origine qui ne fonctionnait plus pour cette version de tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a51a5a2c-f3f8-414e-aa77-86422060a866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n",
    "#J'avais un problème ici car mon modèle ne s'était pas créé c'était dû au input shape qui manquait de ce que je comprends c'est des histoires de versions de tensor flow\n",
    "#J'ai rajouté la 4ème ligne dans la cellule précédente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "82f0f55b-83b4-43d4-85e9-7fe1a91f9566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, 185, 151], dtype=int32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"je t'aime\"\n",
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "be68b13a-0760-4a16-a0bc-59b440730e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.04170972, -0.01308879,  0.04921211, -0.04347448,\n",
       "         -0.00993432,  0.0307938 ,  0.03554085,  0.0374962 ,\n",
       "         -0.01803453, -0.00540574],\n",
       "        [ 0.04170972, -0.01308879,  0.04921211, -0.04347448,\n",
       "         -0.00993432,  0.0307938 ,  0.03554085,  0.0374962 ,\n",
       "         -0.01803453, -0.00540574],\n",
       "        [ 0.04170972, -0.01308879,  0.04921211, -0.04347448,\n",
       "         -0.00993432,  0.0307938 ,  0.03554085,  0.0374962 ,\n",
       "         -0.01803453, -0.00540574],\n",
       "        [ 0.03508558, -0.00691645,  0.04332891, -0.02643063,\n",
       "          0.02824534, -0.03233401, -0.00267701,  0.01194036,\n",
       "         -0.01221845,  0.0302863 ],\n",
       "        [-0.04643903,  0.04642668, -0.02902323,  0.0206237 ,\n",
       "         -0.01432235, -0.03569045, -0.0480106 , -0.03034617,\n",
       "         -0.00200113,  0.00768837]]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([embedded_docs[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6dab2e8d-b4f3-4db7-8615-cc28041caa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "[[[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.03508558 -0.00691645  0.04332891 -0.02643063  0.02824534\n",
      "   -0.03233401 -0.00267701  0.01194036 -0.01221845  0.0302863 ]\n",
      "  [-0.04643903  0.04642668 -0.02902323  0.0206237  -0.01432235\n",
      "   -0.03569045 -0.0480106  -0.03034617 -0.00200113  0.00768837]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.00776789 -0.01692021  0.04038301  0.0281355  -0.04011698\n",
      "    0.02229091  0.00217606  0.00241995  0.047455    0.0134802 ]\n",
      "  [ 0.02414807 -0.03905065  0.00434046  0.039922   -0.00610573\n",
      "   -0.03142376  0.0149148   0.0148196   0.04865447 -0.00376258]\n",
      "  [-0.00558441  0.02370075  0.02026871  0.01856205 -0.03537309\n",
      "   -0.03994163 -0.02714728 -0.01549276 -0.04908932  0.04366804]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.01635173  0.01477155 -0.02947416  0.0272986  -0.0212079\n",
      "    0.02891922  0.01252587 -0.01019554  0.04921475 -0.02420174]\n",
      "  [ 0.01526881  0.0249241  -0.00160104 -0.04904485  0.02829092\n",
      "    0.0274315  -0.00376324  0.01915891 -0.02360101  0.03920667]\n",
      "  [-0.02920404  0.03802541 -0.01502867 -0.03710892 -0.0130772\n",
      "    0.0439187   0.02536703 -0.03776131  0.01613405  0.0344139 ]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.00776789 -0.01692021  0.04038301  0.0281355  -0.04011698\n",
      "    0.02229091  0.00217606  0.00241995  0.047455    0.0134802 ]\n",
      "  [ 0.02414807 -0.03905065  0.00434046  0.039922   -0.00610573\n",
      "   -0.03142376  0.0149148   0.0148196   0.04865447 -0.00376258]\n",
      "  [ 0.02588365 -0.02547668  0.02846781 -0.00055627 -0.04630969\n",
      "    0.01104252  0.04494042  0.04731177 -0.02164068 -0.02031424]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [-0.02006055  0.00225071 -0.01825356  0.0195036   0.02204556\n",
      "    0.00101357  0.0069427  -0.01972032  0.02355735 -0.00038307]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.00868504  0.0319999  -0.03527991  0.04921574 -0.02530816\n",
      "   -0.0150855  -0.03894999  0.04393499  0.02408605 -0.01203329]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.03508558 -0.00691645  0.04332891 -0.02643063  0.02824534\n",
      "   -0.03233401 -0.00267701  0.01194036 -0.01221845  0.0302863 ]\n",
      "  [ 0.02125767  0.03793183 -0.02776359  0.02223373  0.00973704\n",
      "    0.03198336 -0.0113178   0.03301955  0.02845373  0.02929694]\n",
      "  [-0.04501693  0.01467644  0.00667573 -0.01103475  0.01823727\n",
      "    0.03397597  0.03064723 -0.01842523 -0.01076896 -0.04126468]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.00776789 -0.01692021  0.04038301  0.0281355  -0.04011698\n",
      "    0.02229091  0.00217606  0.00241995  0.047455    0.0134802 ]\n",
      "  [-0.00493941 -0.01820016  0.01099843 -0.01688848 -0.0313346\n",
      "    0.02455014 -0.00383264  0.04115695  0.02209852  0.00180073]\n",
      "  [ 0.01681309 -0.00460704 -0.0413432  -0.00402181  0.03251528\n",
      "    0.00702946  0.04723303  0.03910209  0.0172906   0.02728998]]]\n"
     ]
    }
   ],
   "source": [
    "encoded_total = model.predict(np.array(embedded_docs)) #toutes nos phrases traduites en matrices\n",
    "print(encoded_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a9fc2-4f79-4a49-96ca-c4fd8bea7917",
   "metadata": {},
   "source": [
    "On revient au second problème que j'évoquais précédemment : en fait ce n'est pas très grave d'avoir destructurée mes paires, maintenant ce que je vais faire c'est simplement séparer en encoder vs decoder les phrases selon mes indices (pair --> encoder (phrase française), impair --> decoder (phrase anglaise) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8ad317e1-5fc3-45cd-bd43-490b4cb0d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.03508558 -0.00691645  0.04332891 -0.02643063  0.02824534\n",
      "   -0.03233401 -0.00267701  0.01194036 -0.01221845  0.0302863 ]\n",
      "  [-0.04643903  0.04642668 -0.02902323  0.0206237  -0.01432235\n",
      "   -0.03569045 -0.0480106  -0.03034617 -0.00200113  0.00768837]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.01635173  0.01477155 -0.02947416  0.0272986  -0.0212079\n",
      "    0.02891922  0.01252587 -0.01019554  0.04921475 -0.02420174]\n",
      "  [ 0.01526881  0.0249241  -0.00160104 -0.04904485  0.02829092\n",
      "    0.0274315  -0.00376324  0.01915891 -0.02360101  0.03920667]\n",
      "  [-0.02920404  0.03802541 -0.01502867 -0.03710892 -0.0130772\n",
      "    0.0439187   0.02536703 -0.03776131  0.01613405  0.0344139 ]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [-0.02006055  0.00225071 -0.01825356  0.0195036   0.02204556\n",
      "    0.00101357  0.0069427  -0.01972032  0.02355735 -0.00038307]]\n",
      "\n",
      " [[ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.04170972 -0.01308879  0.04921211 -0.04347448 -0.00993432\n",
      "    0.0307938   0.03554085  0.0374962  -0.01803453 -0.00540574]\n",
      "  [ 0.03508558 -0.00691645  0.04332891 -0.02643063  0.02824534\n",
      "   -0.03233401 -0.00267701  0.01194036 -0.01221845  0.0302863 ]\n",
      "  [ 0.02125767  0.03793183 -0.02776359  0.02223373  0.00973704\n",
      "    0.03198336 -0.0113178   0.03301955  0.02845373  0.02929694]\n",
      "  [-0.04501693  0.01467644  0.00667573 -0.01103475  0.01823727\n",
      "    0.03397597  0.03064723 -0.01842523 -0.01076896 -0.04126468]]]\n"
     ]
    }
   ],
   "source": [
    "#On sépare les phrases françaises des phrases anglaises (on suppose donc que l'embedding n'a pas modifié l'ordre ce qui devrait être le cas) \n",
    "encoder_input = encoded_total[::2]  # 0, 2, 4, 6 → français\n",
    "decoder_input = encoded_total[1::2]  # 1, 3, 5, 7 → anglais\n",
    "print(encoder_input) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793ad25-dc6f-4eb8-b8be-816ba0045e7e",
   "metadata": {},
   "source": [
    "Je pense avoir compris tout ce qui précède là je fais un copié-collé de Chat pour construire mes modèles encodeur decodeur et comprendre un peu mieux comment ça marche. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d03b847f-3762-417a-b45a-1c5647f771aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,500</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │      \u001b[38;5;34m5,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │      \u001b[38;5;34m5,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),      │     \u001b[38;5;34m19,200\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m),   │     \u001b[38;5;34m19,200\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m500\u001b[0m)    │     \u001b[38;5;34m32,500\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,900</span> (316.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,900\u001b[0m (316.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,900</span> (316.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,900\u001b[0m (316.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "\n",
    "# Paramètres\n",
    "vocab_size = 500\n",
    "embedding_dim = 10\n",
    "latent_dim = 64\n",
    "sent_length = 5  # nombre de tokens par phrase\n",
    "\n",
    "# --- Encodeur ---\n",
    "encoder_inputs = Input(shape=(sent_length,))  # on passe des indices\n",
    "enc_emb = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(encoder_inputs)\n",
    "_, state_h, state_c = LSTM(latent_dim, return_state=True)(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# --- Décodeur ---\n",
    "decoder_inputs = Input(shape=(sent_length,))  # indices aussi\n",
    "dec_emb = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# --- Modèle complet ---\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad0b738-92d3-47b6-8691-92a835c60797",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padded_fr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ici, pas d'Embedding manuelle avant\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit([padded_fr, decoder_input], decoder_target, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'padded_fr' is not defined"
     ]
    }
   ],
   "source": [
    "# Ici, pas d'Embedding manuelle avant\n",
    "model.fit([padded_fr, decoder_input], decoder_target, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b2e63-d5d7-47e2-b12e-58f5f1160bcf",
   "metadata": {},
   "source": [
    "Le problème ici c'est que je n'ai pas séparé dès le début mes phrases françaises de mes phrases anglaises. Donc j'ai des petits problèmes ici. Je fais une version corrigé où j'explique ce qui fonctionne pas et ce qui diffère de ce que j'ai fait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378124ab-2823-4e6a-b8b2-9aaa5897c1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
